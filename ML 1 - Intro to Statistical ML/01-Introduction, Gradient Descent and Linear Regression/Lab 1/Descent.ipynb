{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c3ab784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (10000, 1) y.shape = (10000,) \n",
      "\n",
      "[ 0.58262411 -1.31093021 -0.76251627 ... -0.22425893  0.17581895\n",
      " -0.93942432]\n",
      "[[ 1.          1.          1.         ...  1.          1.\n",
      "   1.        ]\n",
      " [ 0.58262411 -1.31093021 -0.76251627 ... -0.22425893  0.17581895\n",
      "  -0.93942432]]\n",
      "Theta (1, 2)\n",
      "(1, 2) (2, 10000) (1, 10000)\n",
      "[[-0.00474389  0.09036748]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x, y = make_regression(n_samples=10**4, n_features=1, n_informative=1, \n",
    "                        random_state=0, noise=35) \n",
    "print('x.shape = %s y.shape = %s' %(x.shape, y.shape),'\\n')\n",
    "# Loading the data\n",
    "\n",
    "X=x.reshape((-1,))\n",
    "print(X)\n",
    "Y=y\n",
    "\n",
    "# Creating an array of ones for algebraic calculation\n",
    "ones = [1] * len(X)\n",
    "\n",
    "# Main Logic\n",
    "\n",
    "# Here array of ones will be concatenated with X and transpose will be perform\n",
    "\n",
    "# This signifies that matrix multiplication can help to obtain new value\n",
    "\n",
    "# of theta 0 and theta 1\n",
    "X = np.transpose(np.concatenate((np.array([ones]).reshape(-1, 1),\n",
    "np.array([X]).reshape(-1, 1)), axis=1))\n",
    "print(X)\n",
    "\n",
    "# [[1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n",
    "# [0.8 1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6]]\n",
    "\n",
    "# Same declaring starting value of two thetas, theta 0 and theta 1,\n",
    "\n",
    "# Setting value to 0, this means GD will start finding optimal value from 0\n",
    "\n",
    "zeroes = [0] * X.shape[0]\n",
    "theta = np.array([zeroes])\n",
    "#theta = np.array([[np.mean(y),np.mean(y)+np.std(y)/3]])\n",
    "print('Theta',theta.shape)\n",
    "# [[0 0]]\n",
    "# Defining the learning rate\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "htheta = np.dot(theta, X)\n",
    "\n",
    "print(theta.shape, X.shape, htheta.shape)\n",
    "\n",
    "# (1, 2) (2, 10) (1, 10)\n",
    "diff_theta = htheta - Y\n",
    "\n",
    "partial_derivative_theta = np.dot(diff_theta, np.transpose(X)) / len(Y)\n",
    "\n",
    "# Implementing the formula define above\n",
    "\n",
    "theta = theta - learning_rate * partial_derivative_theta\n",
    "\n",
    "print(theta)\n",
    "\n",
    "# New Value of theta 0 and theta 1\n",
    "# [[0.0111  0.02055]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d88f1",
   "metadata": {},
   "source": [
    "## Now to optimized this value, a for loop can be defined with which it will run until the previous theta and new calculated theta becomes zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c4f8e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30374865  9.25694661]]\n",
      "CPU times: user 3.09 s, sys: 1.1 s, total: 4.19 s\n",
      "Wall time: 955 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 0.01\n",
    "# Threshold for iterating the loop\n",
    "max_iter = 4000\n",
    "# Appending all new values of theta (4000 theta values)\n",
    "new_theta = []\n",
    "for i in range(max_iter):\n",
    "    htheta = np.dot(theta, X)\n",
    "    diff_theta = htheta - Y\n",
    "    partial_derivative_theta = np.dot(diff_theta, np.transpose(X)) / len(Y)\n",
    "    theta = theta - learning_rate * partial_derivative_theta\n",
    "    new_theta.append(theta)\n",
    "print(new_theta[max_iter-1])\n",
    "# Therefore the optimal value would be\n",
    "# [[0.2455339  0.50855582]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384787f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.10180864  8.95319796 10.80458729 12.65597661 14.50736593 16.35875525\n",
      " 18.21014458 20.0615339  21.91292322 23.76431254]\n",
      "R-Squared of the Model is:  [-2590.75118854]\n"
     ]
    }
   ],
   "source": [
    "# Loading the same data again\n",
    "X = [0.8, 1, 1.2, 1.4, 1.6, 1.8, 2, 2.2, 2.4, 2.6]\n",
    "Y = [0.7, 0.65, 0.9, 0.95, 1.1, 1.15, 1.2, 1.4, 1.55, 1.5]\n",
    "Y = np.array([Y])\n",
    "X = np.array([X])\n",
    "# Feteching the optimized theta 0 and theta 1 value\n",
    "theta0 = new_theta[max_iter-1][0][0]\n",
    "theta1 = new_theta[max_iter-1][0][1]\n",
    "# Imputing X into an equation to predict Y\n",
    "pred_y = theta0 + (theta1 * X.reshape(-1,1)).sum(axis=1)\n",
    "print(pred_y)\n",
    "# [0.652379   0.75409007 0.85580115 0.95751223 1.05922331 1.16093438\n",
    "# 1.26264546 1.36435654 1.46606762 1.5677787 ]\n",
    "# Computing the mean for calculating r-squared\n",
    "mean_y =  Y.mean()\n",
    "# Computing Explained Sum of Squares\n",
    "ess = ((Y - mean_y) ** 2).sum(axis=1)\n",
    "# Computing Residual Sum of Squares\n",
    "rss = ((Y - pred_y) ** 2).sum(axis=1)\n",
    "# Computing R-Squared\n",
    "rsquared = 1 - (rss/ess)\n",
    "print(\"R-Squared of the Model is: \", rsquared)\n",
    "# R-Squared of the Model is:  [0.96206043]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
