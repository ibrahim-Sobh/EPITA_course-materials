{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Auto encoders\n\nAuto-encoder and its variants are models that can be used for several things: \n\n- data compression and dimensionality reduction\n- Denoising, recolorisation or super resolution\n- anomaly detection \n\nIn this notebook we will train our first auto-encoder do to MNIST image reconstruction\n",
   "metadata": {
    "cell_id": "00000-6deedf94-3ff2-4fa4-9ba6-2715f6643b0c",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "###  First auto-encoder without convolutions\n\n\nLoad the mnist dataset into train and test datasets, resize it  normalize them with a minmax scaler",
   "metadata": {
    "cell_id": "00001-2498bb5f-efc3-428d-8306-310e68885d6d",
    "output_cleared": false,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-c1d52bd1-e229-4a65-af5a-8c8bf842404e",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Part one the encoder: its goal is to take an original data and reduce its dimension (here to dimension=30)\n\nCreate a first model with (with functional api if keras) with the following layers : \n\n- A dense Relu layer with 300 neurones\n- A dense Relu layer with 30 neurones\n\nName it  encoder\n",
   "metadata": {
    "cell_id": "00003-bdd183a9-7173-4119-8f41-75e04d852bae",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-3f5b5b46-5605-4d1e-94f1-d0da22d84029",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now, the decoder. It is the part that takes the compressed data from the encoder and tries to decode it to the original image\n\n\nCreate a second model with the following layers : \n\n- Relu Dense 200\n- Sigmoid Dense 28*28. \n\nWe use sigmoid at the end because MNIST dataset pixels are either black or white. So we can treat that as a classification problem : the output just classify each pixel of the original image\n\n",
   "metadata": {
    "cell_id": "00003-c28545fd-8398-4100-b304-2873b037c519",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-b65c463f-7810-4fbe-9f36-fb9c42de66da",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Create an auto-encoder model which is the assembly of both the encoder and the decoder",
   "metadata": {
    "cell_id": "00007-6793340d-1afd-448d-adb4-6bb857457a08",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-6e5e3a27-b8f2-444c-a726-7380a4957d1e",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Train the whole auto-encoder model on the training set. What are the labels that must be used for the .fit method ?",
   "metadata": {
    "cell_id": "00003-a4d37965-27ee-424e-83cd-96b5fc006db0",
    "output_cleared": false,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-c61082bf-7df5-4643-a87c-e28a780020c6",
    "execution_millis": 2,
    "execution_start": 1607341917450,
    "output_cleared": false,
    "source_hash": "b623e53d",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Feed some images to the model and display the reconstructed images along with the original images. \n\n",
   "metadata": {
    "cell_id": "00011-328aa606-2ee9-4d28-9f7e-5cbb2ee2d283",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-828ce6e0-1818-43ff-afbd-5409ebe3b169",
    "execution_millis": 423,
    "execution_start": 1607341917454,
    "output_cleared": false,
    "source_hash": "54fdbf98",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## CNN based Auto-encoder\n\nWe can of course have auto-encoder with convolutions ! \n\nWe will replace\n\n- Dense layers by convolution layers in the encoder model and add some maxPooling after each convolution\n- Dense layers by Upsampling2D layers in the decoder model\n\n",
   "metadata": {
    "cell_id": "00013-ea646998-ad7b-400a-a154-0040dd2e880c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "1. Create an Upsampling2D layer with Keras\n\n2. Calculate the output of the layer and store the result in the upsampled variable on the array created above.\n\nReacreate the encoder, decoder and auto-coder model as previously",
   "metadata": {
    "cell_id": "00005-2f0a2d62-2c46-4db3-abef-26d36c5cdf95",
    "output_cleared": false,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-29ef2790-f530-4cc7-a232-0eecf29a49c4",
    "execution_millis": 1,
    "execution_start": 1607341930915,
    "output_cleared": false,
    "source_hash": "572a2d1f",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Reload the MNIST dataset and do the proper scaling and resizing (rember, keras convolutions expects to see a 4D array with the dimensions (nb_exemple, n_col, n_row, n_channel)",
   "metadata": {
    "cell_id": "00016-cedb8680-88ff-45ca-9520-4ec50491c2ae",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-1d47c672-682b-4bf9-b751-e84dbbaff8aa",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Train the auto-encoder model. Display some reconstructed images. Does it work better than the previous model?",
   "metadata": {
    "cell_id": "00007-068f52cb-1fc6-4307-9722-61619e5372a0",
    "output_cleared": false,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-db1faaaf-2d28-4d4f-b4fa-6ef6ab1771b6",
    "execution_millis": 68,
    "execution_start": 1607341930916,
    "output_cleared": false,
    "source_hash": "ff241c96",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Bonus : Denoising auto-encoder. \n\nLet's say that we have two version of our images : \n\n- image with noise\n- the same image without noise. \n\nWe can ask our auto-encoder to reconstruct clean images from noisy images\n\n",
   "metadata": {
    "cell_id": "00020-a13886cc-fd03-4152-af66-390358c08d56",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Load the Mnist dataset. \n",
   "metadata": {
    "cell_id": "00021-45b51564-d730-439e-98ac-fbeec5422ee5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00022-fc94d0ad-39d1-4731-9e49-dc2609f3a96a",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "With the noise function bellow, create a corrupted version of MNIST by adding some noise",
   "metadata": {
    "cell_id": "00023-12847186-ab52-4f64-a882-d6374219e81d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00024-54c7385e-350a-44d0-8bfe-5c219afa9b09",
    "deepnote_cell_type": "code"
   },
   "source": "def noise(array):\n    \"\"\"\n    Adds random noise to each image in the supplied array.\n    \"\"\"\n\n    noise_factor = 0.4\n    noisy_array = array + noise_factor * np.random.normal(\n        loc=0.0, scale=1.0, size=array.shape\n    )\n\n    return np.clip(noisy_array, 0.0, 1.0)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Display some noisy images and check you can still recognize mnist dataset ",
   "metadata": {
    "cell_id": "00025-64ff3d1b-72e7-43d1-b2ad-01c31c607b43",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00026-f6fd2a49-a86f-4372-aa51-84dccd54040e",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Instanciate a new version of the CNN auto-encoder. Train it now to reconstruct clean images from noisy ones. ",
   "metadata": {
    "cell_id": "00027-73459474-29b4-45b0-b5df-1b72ba0a1866",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00028-05a445c1-fffa-4909-9b60-2b94478a6f99",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Feed some noisy image to the network and check that it outputs some cleaned images with matplotlib",
   "metadata": {
    "cell_id": "00029-a84d330e-a52d-47bc-a878-aa8a61597f01",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00030-304edfb9-3857-4d9b-87d6-4c761e9b8abb",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Search and Think about other applications of auto-encoder ",
   "metadata": {
    "cell_id": "00031-1ecc4bf6-713e-4e0f-b777-956bde90290d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00032-4a08beaf-b031-4e0f-b8c5-da537af82158",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6b859965-b858-4b8d-a841-009599aef86e' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e0b3d3f1-f036-4cbe-a76a-8c423f4604fc",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 }
}