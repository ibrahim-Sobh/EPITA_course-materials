{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "course2_embedding_illustration_ex.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPeikwq1xZaQ"
      },
      "source": [
        "The goal is to check that the vector result of *king - man + woman* is close to *queen* vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LfCrTRvxoa7"
      },
      "source": [
        "## Try with a spaCy pretrained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "762mKs9CxSdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e81b96-008a-4ac6-e876-c1b14b780bab"
      },
      "source": [
        "import spacy\n",
        "import spacy.cli\n",
        "from scipy import spatial\n",
        "# we dowload a nlp english model (with a pre-trained 300-dimension embedding) \n",
        "spacy.cli.download(\"en_core_web_md\")\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVvKiD8zyfL_"
      },
      "source": [
        "spaCy allows to compute directly a pre-trained 300-dimension embedding for every word\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2z6QyoInHBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e45cc8-6091-4073-8e97-6486d5adae7e"
      },
      "source": [
        "king = nlp.vocab['king']\n",
        "king.vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.0644e-01, -5.1205e-01,  6.4921e-03, -2.9194e-01, -5.6515e-01,\n",
              "       -1.1523e-01,  7.7274e-02,  3.3561e-01,  1.1593e-01,  2.3516e+00,\n",
              "        5.1773e-02, -5.4229e-01, -5.7972e-01,  1.3220e-01,  2.8430e-01,\n",
              "       -7.9592e-02, -2.6762e-01,  1.8301e-01, -4.1264e-01,  2.0459e-01,\n",
              "        1.4436e-01, -1.8714e-01, -3.1393e-01,  1.7821e-01, -1.0997e-01,\n",
              "       -2.5584e-01, -1.1149e-01,  9.6212e-02, -1.6168e-01,  4.0055e-01,\n",
              "       -2.6115e-01,  5.3777e-01, -5.2382e-01,  2.7637e-01,  7.2191e-01,\n",
              "        6.0405e-02, -1.7922e-01,  1.8020e-01, -1.4381e-01, -1.4795e-01,\n",
              "       -8.1394e-02,  5.8282e-02,  2.2964e-02, -2.6374e-01,  1.0704e-01,\n",
              "       -4.5425e-01, -1.9964e-01,  3.7720e-01, -9.7784e-02, -3.1999e-01,\n",
              "       -7.8509e-02,  6.1502e-01,  7.1643e-02, -3.0930e-02,  2.1508e-01,\n",
              "        2.5280e-01, -3.1643e-01,  6.6698e-01,  1.9813e-02, -3.2311e-01,\n",
              "        2.9266e-02, -4.1403e-02,  2.8346e-01, -7.9143e-01,  1.3327e-01,\n",
              "        7.7231e-02, -1.8724e-01, -3.3146e-01, -2.0797e-01, -6.9326e-01,\n",
              "       -2.3412e-01, -6.8752e-02,  3.8252e-02, -3.2459e-01, -8.3609e-03,\n",
              "        1.2945e-01, -2.8316e-01, -5.7546e-01,  2.4336e-01,  5.6433e-01,\n",
              "       -7.1285e-01, -5.4738e-03, -2.3305e-01, -7.1578e-02,  4.8301e-01,\n",
              "       -3.4312e-01,  2.7365e-01, -1.1771e+00, -6.5800e-01, -1.9009e-01,\n",
              "        7.4287e-03,  3.2977e-01, -1.6647e-01,  2.6851e-01,  1.1811e-01,\n",
              "       -6.2440e-02, -4.9987e-02,  7.1011e-04, -5.6201e-02, -2.6696e-01,\n",
              "        3.1351e-01,  4.3955e-01, -8.8727e-02, -1.2315e-01,  1.8855e-01,\n",
              "       -1.0834e+00, -3.3041e-01,  5.7325e-01, -3.9947e-01,  1.4852e-02,\n",
              "       -3.6787e-01,  3.7842e-01, -2.8962e-01, -7.0543e-02, -5.8699e-02,\n",
              "        5.3076e-01, -1.2736e-01, -3.5724e-01, -1.5007e-01,  1.3823e-02,\n",
              "       -1.9497e-01, -3.7189e-01,  2.6255e-01, -7.6826e-02,  8.4217e-02,\n",
              "       -5.3640e-01,  1.7393e-01, -1.4698e-01, -1.1068e-01,  1.7709e-01,\n",
              "       -3.9556e-01,  1.0433e-01,  9.2675e-03, -1.2282e-01, -3.9842e-01,\n",
              "       -2.7758e-01, -6.9369e-01,  7.0128e-02,  8.2794e-02,  4.8342e-02,\n",
              "       -2.7038e+00, -1.6812e-01,  3.1413e-01,  2.4313e-02, -3.6423e-02,\n",
              "        1.9292e-01,  4.4872e-01, -4.5427e-01, -3.7271e-01, -9.9532e-01,\n",
              "       -1.3411e-01, -6.0312e-01,  1.6642e-01, -2.4611e-02,  6.6891e-01,\n",
              "        6.3476e-02, -1.1327e+00, -3.3786e-01, -1.2576e-02,  3.5344e-01,\n",
              "        2.6643e-01, -1.9404e-01, -1.9516e-01,  6.3670e-01,  2.1373e-01,\n",
              "       -2.8936e-01, -6.8847e-02, -1.9738e-01, -3.5305e-01,  1.0219e-01,\n",
              "        1.1744e-01,  3.7159e-02,  4.1041e-01, -1.3766e-02, -1.0325e-02,\n",
              "        1.0461e-02,  3.0697e-02, -3.3016e-01,  2.4668e-01, -2.6058e-01,\n",
              "        2.8665e-01, -7.8507e-02,  6.8945e-03,  1.0980e-01, -6.4179e-01,\n",
              "        2.4617e-03, -2.4693e-01, -1.1188e-02,  3.0838e-01,  4.5557e-01,\n",
              "       -6.2189e-01,  1.4873e-01,  3.5440e-01,  2.8642e-01, -2.4211e-01,\n",
              "       -1.2404e-01,  2.3326e-01,  1.9555e-01, -1.2425e-02,  1.9920e-01,\n",
              "       -1.7935e-01,  5.2031e-01, -4.3666e-01,  8.6211e-02,  1.7282e-01,\n",
              "        6.5266e-02,  2.8701e-01,  6.0238e-01,  3.1843e-01, -4.7646e-01,\n",
              "       -2.1181e-02, -2.7726e-01,  4.0253e-01,  3.9968e-01,  1.8580e-02,\n",
              "       -6.2663e-01,  3.4149e-01,  4.4687e-01, -4.6135e-01,  4.4174e-01,\n",
              "       -5.7541e-02, -1.9038e-02, -2.2626e-01,  5.8452e-02, -4.6681e-02,\n",
              "       -5.3295e-03, -1.8257e-03,  4.8565e-01, -4.6144e-01, -4.5877e-01,\n",
              "       -1.5891e-01,  1.3037e-01, -2.9183e-01,  6.9206e-02, -4.9825e-02,\n",
              "        5.5077e-01,  1.4730e-01, -1.9255e-01, -2.3916e-01, -1.9319e-01,\n",
              "        1.5643e-01,  3.3491e-01, -3.1913e-01,  2.0674e-01,  6.4556e-02,\n",
              "       -2.3195e-01,  1.2657e-01, -2.5131e-03,  1.1079e-01,  3.0436e-01,\n",
              "        6.9529e-02,  1.1027e-01,  2.6285e-01, -2.3103e-01, -2.8933e-01,\n",
              "       -5.0675e-02, -8.9796e-02,  2.5816e-01, -8.0917e-02,  3.3160e-01,\n",
              "       -3.5930e-01,  2.8336e-01,  1.4145e-01,  2.9012e-01,  1.5677e-01,\n",
              "        1.3225e-01, -5.0090e-01,  2.2110e-01,  6.9609e-01, -9.6917e-02,\n",
              "       -2.4966e-02, -2.9391e-01, -3.1240e-01, -3.8031e-01, -2.0604e-01,\n",
              "        1.5959e-01, -5.6155e-01,  2.9170e-01, -5.0459e-01,  6.5684e-02,\n",
              "        5.8594e-01,  1.3003e-02,  6.5874e-01, -4.7811e-01,  2.8794e-01,\n",
              "        3.5918e-01,  4.3347e-01, -4.2480e-01,  3.5892e-01, -6.0925e-01,\n",
              "       -7.1236e-01,  2.9490e-01, -2.1479e-01,  2.5658e-01, -1.9358e-01,\n",
              "        1.1057e+00,  2.2862e-01,  2.1859e-01, -1.9044e-01, -1.0253e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOknO0BRzSRy",
        "outputId": "da2d49de-4984-4c94-b152-0d8d56acec73"
      },
      "source": [
        "king.vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWSerK8SsYMd"
      },
      "source": [
        "# Question 1: Compute the vector \"king - man + woman\" and try to show that the result is close to the vector representation of the word \"queen\" ;\n",
        "# a good way to do it is, for example, to find the 10 closest word (among the nlp.vocab words) from the results of \"king - man + woman\" and to show\n",
        "# that \"queen\" is one of them (if not the best)\n",
        "\n",
        "# The distance we need for that is the cosine similarity, it can be define from the spatial.distance.cosine function imported from the scipy library\n",
        "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
        "\n",
        "# Start the exercice here\n",
        "# Hint: use a loop on nlp.vocab (all the words defined in spaCy vocabulary) ; for each \"word\" in the vocabulary you can check if the word has an embedding vector (\"word.has_vector\"), if the word is in\n",
        "# lower case (\"word.is_lower\") and is alphanumeric (\"word.is_alpha\"). Try to consider only the relevant words for the exercice\n",
        "# ??????"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdfvSzyFxsz5"
      },
      "source": [
        "## Try with a pretrained Word2Vec embedding model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DnQ8h8IhJO4"
      },
      "source": [
        "**Important** To prevent RAM crash in the execution environment, please restart from here the running environment (Execution -> Restart the running environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkPTJ9oLv_Hv"
      },
      "source": [
        "import gensim# Load pretrained vectors from Google\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvv6t5uyzffL"
      },
      "source": [
        "We load the pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased embedding models (100-dimension embedding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qm9ua_Tv_P6"
      },
      "source": [
        "import gensim.downloader as api\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jczj7qXfv_TB"
      },
      "source": [
        "king = word_vectors['king']\n",
        "\n",
        "print(king)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7vxg9DqzreT"
      },
      "source": [
        "king.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhVZa8Ufv_bE"
      },
      "source": [
        "# Question 2: This time with the GoogleNews embedding model, try to show once again that \"king - man + woman\" is close to the vector representation of the word \"queen\" ;\n",
        "# Hint: There is a pre-defined function in the gensim \"word_vectors\" object (define just above) that allows to get this result quite easily\n",
        "\n",
        "# ??????????????"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ0XN3j7i4Fk"
      },
      "source": [
        "## Try with fastText embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvKq5vbXi8up"
      },
      "source": [
        "**Important** To prevent RAM crash in the execution environment, please restart from here the running environment (Execution -> Restart the running environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUCj7-bGjc73"
      },
      "source": [
        "#Download, extract and load Fasttext word embedding model\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gunzip /content/cc.en.300.bin.gz\n",
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suVw4N4cjAXc"
      },
      "source": [
        "Load the english fastText model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YH4W8m-i7P6"
      },
      "source": [
        "import fasttext \n",
        "\n",
        "model = fasttext.load_model(\"/content/cc.en.300.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNSYa7qm4gyN"
      },
      "source": [
        "model.get_word_vector(\"king\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXHl3VkijDWQ"
      },
      "source": [
        "It is possible to get directly the nearest neighbors of a specific word (or even n-gram)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwxBjH-YjFg1"
      },
      "source": [
        "model.get_nearest_neighbors(\"king\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPFj4l47jHx-"
      },
      "source": [
        "# Question 3: This time with the fastText embedding model, try to show once again that \"king - man + woman\" is close to the vector representation of the word \"queen\" ;\n",
        "# Hint: There is a pre-defined function in the fastText model, 'get_analogies', that allows to get this result quite easily"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}