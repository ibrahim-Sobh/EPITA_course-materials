{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "course2_embedding_illustration_solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPeikwq1xZaQ"
      },
      "source": [
        "The goal is to check that the vector result of *king - man + woman* is close to *queen* vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LfCrTRvxoa7"
      },
      "source": [
        "## Try with a spaCy pretrained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "762mKs9CxSdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78844f95-d31a-4178-bf74-74563cb32c1e"
      },
      "source": [
        "import spacy\n",
        "import spacy.cli\n",
        "from scipy import spatial\n",
        "# we dowload a nlp english model (with a pre-trained 300-dimension embedding) \n",
        "spacy.cli.download(\"en_core_web_md\")\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVvKiD8zyfL_"
      },
      "source": [
        "spaCy allows to compute directly a pre-trained 300-dimension embedding for every word\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2z6QyoInHBJ",
        "outputId": "f97b6d8e-e77c-493c-9cdf-7fc7d2230d1d"
      },
      "source": [
        "king = nlp.vocab['king']\n",
        "king.vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.1542e-01, -3.5068e-01,  4.2923e-01, -5.3825e-01, -1.8480e-01,\n",
              "       -3.1082e-01,  2.9196e-01, -7.1030e-01, -2.3867e-01,  1.8471e+00,\n",
              "       -3.6446e-01, -5.1282e-01,  1.2210e-01,  3.8909e-01, -7.3204e-02,\n",
              "        3.5462e-02,  3.3289e-01,  6.6466e-01,  2.7175e-02,  4.2021e-01,\n",
              "       -1.4520e-01,  3.7991e-01, -6.0520e-01,  1.0695e-01, -6.4716e-01,\n",
              "       -1.0739e-02, -3.9754e-01,  3.8857e-01, -2.0134e-01,  6.9813e-01,\n",
              "       -3.2411e-01,  7.3085e-01, -1.0930e-01, -2.3511e-01,  1.8482e-01,\n",
              "       -1.1595e-01, -7.1003e-01, -2.2974e-01, -4.1979e-01,  8.1004e-03,\n",
              "       -1.0504e-01, -4.4802e-01, -7.3928e-02, -4.2380e-01,  2.8482e-01,\n",
              "       -7.4517e-02,  9.8161e-02,  6.4602e-01, -2.5832e-01, -2.0452e-02,\n",
              "       -6.6863e-02,  5.1501e-01,  1.6758e-01,  1.2329e-01,  1.9636e-01,\n",
              "        1.1958e-01, -1.8296e-01, -1.4325e-01, -2.7758e-01,  5.0597e-02,\n",
              "       -6.6122e-02, -1.8920e-01,  3.3300e-01,  2.5319e-01,  6.6355e-01,\n",
              "        6.6735e-01,  4.9969e-01,  1.5481e-01, -8.4247e-02, -2.2947e-01,\n",
              "       -6.8367e-01, -2.9783e-01, -1.8651e-01, -4.7121e-01,  1.8272e-01,\n",
              "       -3.2604e-01, -6.8030e-02,  7.0073e-01,  3.3159e-01,  7.0393e-02,\n",
              "       -7.6987e-01,  5.9069e-01,  2.0592e-01,  1.7976e-01,  6.9525e-03,\n",
              "        5.7855e-02,  7.2047e-01, -7.7249e-01, -5.4188e-01, -1.2189e-01,\n",
              "       -3.1734e-03, -1.5960e-01,  1.6970e-01, -1.2546e-01,  8.7069e-01,\n",
              "       -4.6478e-01, -1.9302e-01, -4.5618e-01, -1.5419e-01,  8.1190e-01,\n",
              "       -2.0544e-01,  3.9454e-01, -3.1178e-01, -6.4318e-02, -4.4443e-02,\n",
              "       -5.8338e-01, -1.4792e-01,  1.7083e-02,  8.3239e-01, -1.1280e-01,\n",
              "        5.7826e-02,  1.7024e-01, -1.3635e-01, -2.8894e-01, -4.0590e-01,\n",
              "       -5.0685e-02,  4.9856e-01,  6.0885e-02,  1.9437e-01, -1.9811e-01,\n",
              "       -2.2335e-01, -2.5909e-02,  3.9846e-01,  4.4087e-01,  2.3195e-02,\n",
              "        9.8666e-02, -1.3004e-01, -2.0339e-01, -4.2958e-01, -7.9760e-03,\n",
              "       -3.2016e-01, -4.1094e-01, -1.0304e-01, -7.5565e-01,  1.7748e-02,\n",
              "       -2.0037e-01,  1.7185e-01,  2.1787e-01, -3.1685e-01,  2.2068e-02,\n",
              "       -2.5559e+00, -9.9115e-02,  1.8434e-01,  1.2448e-01, -5.9413e-02,\n",
              "       -4.5649e-02,  7.9018e-01,  2.4556e-01, -1.5059e-02, -7.8996e-01,\n",
              "        2.9087e-01, -3.9419e-01,  3.7617e-01,  1.5718e-01,  5.1356e-01,\n",
              "       -3.4219e-01,  5.0628e-02, -3.3254e-01, -1.4157e-01,  3.3355e-01,\n",
              "        4.4398e-01, -2.5451e-01, -3.3201e-02, -2.0958e-01,  3.8870e-01,\n",
              "       -2.4565e-01,  5.2391e-01,  4.3247e-01, -4.1701e-01,  2.9031e-01,\n",
              "       -7.8001e-01,  3.0100e-02, -6.1446e-02, -1.4029e-01, -5.5354e-01,\n",
              "       -1.9175e-01,  6.7279e-01, -1.1104e-01, -3.5486e-01, -2.8601e-01,\n",
              "        1.1720e-01, -4.5021e-01,  1.4004e-01, -5.7484e-01, -2.2531e-01,\n",
              "        4.1572e-01, -1.5950e-01, -2.7877e-01,  7.9785e-02,  1.9120e-02,\n",
              "       -9.8357e-01, -5.6998e-01, -3.4023e-02,  1.7382e-02, -1.7157e-02,\n",
              "       -2.8211e-01,  1.5573e-01, -1.3556e-01, -2.6296e-01, -7.4571e-01,\n",
              "        1.2015e-01,  5.4234e-01,  5.6783e-02, -7.5675e-02,  2.1820e-01,\n",
              "       -2.5679e-01,  2.3552e-01, -2.7111e-02, -1.9342e-01, -3.1088e-01,\n",
              "       -1.0600e-01,  4.9512e-01,  5.7932e-02,  3.8773e-01,  9.3160e-02,\n",
              "       -1.3782e-01,  2.4244e-01,  3.8098e-01,  9.1109e-04,  8.8338e-01,\n",
              "        4.3823e-01, -7.7041e-02,  1.1541e-01,  3.4702e-01,  5.9785e-01,\n",
              "        6.7012e-01, -6.0953e-02, -4.3872e-02, -4.0800e-01,  7.5721e-01,\n",
              "        2.4773e-01,  8.8926e-02, -1.8493e-01, -5.2339e-01,  8.5809e-02,\n",
              "       -6.0880e-01, -7.7463e-02, -2.6829e-01, -3.9021e-01, -1.5002e-01,\n",
              "        5.4297e-01, -4.1076e-01, -9.5215e-02, -2.9787e-01,  1.0041e-01,\n",
              "       -3.7774e-01,  7.5511e-01, -4.3910e-01, -6.1722e-01, -1.0360e+00,\n",
              "        6.9651e-01,  1.4157e-01, -4.4533e-01,  3.2702e-01,  3.8306e-02,\n",
              "        2.6765e-01,  5.4242e-02, -3.0242e-02, -4.5133e-01,  6.2505e-03,\n",
              "        2.7504e-01, -5.2413e-02, -1.9870e-01, -1.7869e-01, -2.4658e-01,\n",
              "       -3.7369e-01,  2.6174e-01,  4.1482e-01, -5.9277e-01,  6.1446e-02,\n",
              "        6.6261e-02,  1.0970e-01, -1.4388e-01, -3.2442e-01, -3.9016e-04,\n",
              "       -2.1392e-01,  3.2963e-01,  5.0402e-01,  1.3454e-01, -5.6133e-01,\n",
              "        1.0422e+00,  5.8985e-01,  1.4473e-01,  1.7745e-01,  1.6160e-01,\n",
              "        3.3230e-01,  2.2909e-01,  1.5774e-01, -3.5463e-01, -4.7642e-01,\n",
              "       -2.5822e-01,  2.3677e-01, -4.0255e-01, -3.5364e-01, -1.6697e-01,\n",
              "        7.0677e-01,  8.4272e-02,  1.1427e-01,  5.8221e-01, -1.0559e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOknO0BRzSRy",
        "outputId": "9df08fb6-60b5-42d1-8788-5536c61c9f08"
      },
      "source": [
        "king.vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWSerK8SsYMd",
        "outputId": "298ef659-03de-4eb4-da6b-02bc610d500a"
      },
      "source": [
        "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
        "\n",
        "king = nlp.vocab['king'].vector\n",
        "man = nlp.vocab['man'].vector\n",
        "woman = nlp.vocab['woman'].vector\n",
        "\n",
        "# Now we find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
        "new_vector = king - man + woman\n",
        "computed_similarities = []\n",
        "\n",
        "for word in nlp.vocab:\n",
        "    # Ignore words without vectors and mixed-case words:\n",
        "    if word.has_vector:\n",
        "        if word.is_lower:\n",
        "            if word.is_alpha:\n",
        "                similarity = cosine_similarity(new_vector, word.vector)\n",
        "                computed_similarities.append((word, similarity))\n",
        "\n",
        "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
        "\n",
        "print([w[0].text for w in computed_similarities[:10]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['king', 'queen', 'commoner', 'highness', 'prince', 'sultan', 'maharajas', 'princes', 'kumbia', 'kings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdfvSzyFxsz5"
      },
      "source": [
        "## Try with a pretrained Word2Vec embedding model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wkVRSgsgtA9"
      },
      "source": [
        "**Important** To prevent RAM crash in the execution environment, please restart from here the running environment (Execution -> Restart the running environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkPTJ9oLv_Hv",
        "outputId": "cefea330-ac75-4a10-e4ad-549fb88a7cea"
      },
      "source": [
        "!pip install  gensim\n",
        "import gensim# Load pretrained vectors from Google\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-04 18:59:14--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.110.45\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.110.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.8.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvv6t5uyzffL"
      },
      "source": [
        "We load the pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased embedding models (100-dimension embedding)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")\n"
      ],
      "metadata": {
        "id": "HSXDo5yJkPN3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jczj7qXfv_TB",
        "outputId": "89588a57-cff4-44cc-e08a-bfb73c2816e4"
      },
      "source": [
        "king = word_vectors['king']\n",
        "\n",
        "print(king)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.32307  -0.87616   0.21977   0.25268   0.22976   0.7388   -0.37954\n",
            " -0.35307  -0.84369  -1.1113   -0.30266   0.33178  -0.25113   0.30448\n",
            " -0.077491 -0.89815   0.092496 -1.1407   -0.58324   0.66869  -0.23122\n",
            " -0.95855   0.28262  -0.078848  0.75315   0.26584   0.3422   -0.33949\n",
            "  0.95608   0.065641  0.45747   0.39835   0.57965   0.39267  -0.21851\n",
            "  0.58795  -0.55999   0.63368  -0.043983 -0.68731  -0.37841   0.38026\n",
            "  0.61641  -0.88269  -0.12346  -0.37928  -0.38318   0.23868   0.6685\n",
            " -0.43321  -0.11065   0.081723  1.1569    0.78958  -0.21223  -2.3211\n",
            " -0.67806   0.44561   0.65707   0.1045    0.46217   0.19912   0.25802\n",
            "  0.057194  0.53443  -0.43133  -0.34311   0.59789  -0.58417   0.068995\n",
            "  0.23944  -0.85181   0.30379  -0.34177  -0.25746  -0.031101 -0.16285\n",
            "  0.45169  -0.91627   0.64521   0.73281  -0.22752   0.30226   0.044801\n",
            " -0.83741   0.55006  -0.52506  -1.7357    0.4751   -0.70487   0.056939\n",
            " -0.7132    0.089623  0.41394  -1.3363   -0.61915  -0.33089  -0.52881\n",
            "  0.16483  -0.98878 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7vxg9DqzreT",
        "outputId": "8905f7e0-5bd2-4436-da68-ad866d26c439"
      },
      "source": [
        "king.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhVZa8Ufv_bE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37e4294-9bdb-4b7d-bc99-71a9b9426ec2"
      },
      "source": [
        "# king - man + woman = queen\n",
        "# cosin similarity between the mean\n",
        "print(word_vectors.most_similar(positive=['woman', 'king'], negative=['man']))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7698541283607483), ('monarch', 0.6843380928039551), ('throne', 0.6755735874176025), ('daughter', 0.6594556570053101), ('princess', 0.6520534753799438), ('prince', 0.6517034769058228), ('elizabeth', 0.6464517712593079), ('mother', 0.6311717629432678), ('emperor', 0.6106470823287964), ('wife', 0.6098655462265015)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvIjjjz3hO35"
      },
      "source": [
        "## Try with fastText embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMbgOjQdhWsr"
      },
      "source": [
        "**Important** To prevent RAM crash in the execution environment, please restart from here the running environment (Execution -> Restart the running environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc2lAe6BiShA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7151ac4c-971c-4c3e-800f-bc90b74ef67c"
      },
      "source": [
        "#Download, extract and load Fasttext word embedding model\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gunzip /content/cc.en.300.bin.gz\n",
        "!pip install fasttext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-04 19:33:26--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: â€˜cc.en.300.bin.gzâ€™\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G  21.9MB/s    in 3m 49s  \n",
            "\n",
            "2022-07-04 19:37:16 (18.7 MB/s) - â€˜cc.en.300.bin.gzâ€™ saved [4503593528/4503593528]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3143847 sha256=7521154d8227e83ff9576b6b29ad2496b3a176fae6e295550955813d1aea5334\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF53Zmjxigo3"
      },
      "source": [
        "Load the english fastText model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhFsoC79iV_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a6c440-363d-46ea-a502-f95462f201c5"
      },
      "source": [
        "import fasttext \n",
        "\n",
        "model = fasttext.load_model(\"/content/cc.en.300.bin\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EVMESt-4jzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532c12f3-3b95-42fa-bec3-ff379aa299af"
      },
      "source": [
        "model.get_word_vector(\"king\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.63642855e-02, -4.38338369e-02, -5.22461310e-02,  2.49765869e-02,\n",
              "        1.59946546e-01,  4.98980191e-03,  2.51637166e-03, -1.62712112e-02,\n",
              "       -6.62135556e-02, -1.67888845e-03, -1.39499649e-01, -5.72493225e-02,\n",
              "       -1.45975351e-01, -1.56568401e-02,  3.75731173e-03,  8.14326331e-02,\n",
              "        9.02080238e-02, -6.22668210e-03, -1.21208653e-01,  8.42568502e-02,\n",
              "        6.83858395e-02,  1.01658493e-01, -5.07243127e-02,  9.16049480e-02,\n",
              "        5.08386921e-03,  6.28780201e-02,  5.67676872e-02,  1.91132650e-01,\n",
              "        4.35085818e-02,  1.80901110e-01, -1.74744725e-02,  7.06654340e-02,\n",
              "       -6.06337450e-02,  3.89074199e-02,  1.44602428e-03, -1.25214964e-01,\n",
              "        8.63592885e-03, -7.98915625e-02, -1.00960366e-01,  4.66771051e-02,\n",
              "        5.39167747e-02,  4.82006092e-03, -2.03307956e-01, -1.17739499e-01,\n",
              "       -1.37199834e-01, -4.92817685e-02, -1.87217459e-01, -7.17959851e-02,\n",
              "       -1.86646730e-02, -9.93231237e-02, -5.15213236e-02, -1.93316743e-01,\n",
              "       -8.94939303e-02, -1.71539113e-01, -1.03669807e-01, -7.04649240e-02,\n",
              "        1.29511207e-01,  5.56146055e-02, -4.56965044e-02, -7.34248012e-03,\n",
              "        6.97860867e-02,  1.69947833e-01,  3.10327169e-02,  5.91522716e-02,\n",
              "       -8.91570747e-02,  1.04047880e-01, -5.08228168e-02,  1.56981260e-01,\n",
              "        1.38354123e-01, -9.97450016e-03,  2.92297285e-02,  2.03259155e-01,\n",
              "       -3.15062096e-03, -6.43643364e-02, -2.74570972e-01,  1.08004212e-01,\n",
              "       -7.50373602e-02, -3.31273973e-02,  1.68551207e-02,  3.04881241e-02,\n",
              "       -3.62115651e-02,  8.74452889e-02,  1.11329509e-02,  2.68645063e-02,\n",
              "       -7.08571821e-03, -2.58087125e-02, -4.53866273e-03, -6.63428903e-02,\n",
              "       -5.25312535e-02, -2.38072332e-02, -1.16000466e-01,  1.33487135e-01,\n",
              "       -2.33370923e-02,  1.01321653e-01, -2.84816176e-02,  6.99471235e-02,\n",
              "        5.94794080e-02, -3.12442761e-02,  9.96296033e-02, -9.60462987e-02,\n",
              "       -3.27447765e-02,  1.32649690e-01, -7.74053261e-02, -3.05452459e-02,\n",
              "       -4.82974909e-02, -9.31103155e-03,  4.92358953e-02,  1.27702221e-01,\n",
              "        1.52136413e-02, -6.89754635e-02,  3.81627008e-02,  1.48964554e-01,\n",
              "        2.59358287e-02,  3.15686166e-02, -3.75460275e-02, -3.22045460e-02,\n",
              "        6.52550533e-03,  6.29867092e-02, -4.78249863e-02, -8.24730843e-02,\n",
              "       -3.23293060e-02, -1.20065711e-01,  2.90956944e-02,  6.78243339e-02,\n",
              "        8.16046149e-02,  2.02703606e-02, -1.39618635e-01,  9.63046476e-02,\n",
              "       -1.42421201e-01, -4.51344661e-02, -1.27089359e-02,  1.10854320e-02,\n",
              "       -3.85885164e-02,  2.25833915e-02, -1.08815163e-01, -1.36975110e-01,\n",
              "        9.15990099e-02,  1.36979327e-01,  2.05856919e-01,  1.61201283e-02,\n",
              "       -8.97449777e-02, -8.50699991e-02,  1.80081427e-02, -1.45724982e-01,\n",
              "       -6.40569925e-02, -2.87944600e-02, -1.85657188e-01, -1.05159611e-01,\n",
              "        8.60162973e-02, -1.19275272e-01,  3.13830888e-03,  4.35946211e-02,\n",
              "       -2.94638574e-02, -5.80169484e-02, -7.43187964e-02, -6.81279004e-02,\n",
              "        4.28178627e-03,  2.47925576e-02, -5.52196279e-02,  4.89809215e-02,\n",
              "        2.41583195e-02, -5.86985052e-03,  1.50820628e-01, -1.71622664e-01,\n",
              "       -2.79987380e-02, -8.41945410e-02,  2.45981030e-02, -5.13311736e-02,\n",
              "        8.11809674e-02, -4.38897684e-02, -3.67027484e-02,  8.58394802e-02,\n",
              "        1.89167447e-02,  9.81604904e-02, -2.10215524e-02, -9.18451697e-02,\n",
              "        4.16197814e-02,  3.72997858e-02, -2.53814217e-02,  7.56689906e-02,\n",
              "       -5.52651398e-02,  5.15166819e-02,  5.78585193e-02, -1.13078147e-01,\n",
              "       -1.31233573e-01,  1.98879652e-02,  5.17351776e-02, -1.33150861e-01,\n",
              "        8.34213104e-03, -3.06397229e-02,  2.26650923e-01,  1.93806678e-01,\n",
              "        2.68921461e-02, -7.12896511e-02,  6.03743792e-02,  9.77210030e-02,\n",
              "        6.09308891e-02, -2.61368863e-02, -5.99689856e-02, -5.24861179e-02,\n",
              "       -4.83104885e-02,  7.28225857e-02, -1.82350785e-01, -5.07587008e-02,\n",
              "        6.97027445e-02, -1.01331189e-01,  1.07080504e-01,  1.28510892e-01,\n",
              "        9.44370925e-02, -1.64818019e-03,  3.74368392e-02,  2.60068737e-02,\n",
              "       -1.58898175e-01,  4.27626036e-02, -1.41406000e-01, -1.06626293e-02,\n",
              "       -8.82082805e-02,  1.92979965e-02,  5.96629195e-02,  5.97821996e-02,\n",
              "       -5.79583198e-02,  3.44996750e-02, -6.58642352e-02,  4.48877513e-02,\n",
              "       -1.86586022e-01, -1.24391131e-01,  1.32317677e-01, -4.36709300e-02,\n",
              "       -4.57718074e-02, -2.56884605e-01, -9.85114276e-02, -1.60375610e-04,\n",
              "        1.09038558e-02,  1.38050532e-02,  9.97474417e-02,  5.01477830e-02,\n",
              "        1.03953376e-01,  1.58712223e-01,  7.36273751e-02, -8.92454609e-02,\n",
              "       -2.21837722e-02, -1.07683539e-02, -5.13628125e-02, -1.06365465e-01,\n",
              "        1.24920994e-01, -2.97540985e-02,  3.98862213e-02, -4.22692448e-02,\n",
              "       -9.01315361e-02,  4.86209616e-02,  2.54198909e-02, -9.57448930e-02,\n",
              "       -3.86590175e-02,  2.03618214e-01,  1.18185788e-01,  5.32859191e-02,\n",
              "       -2.04965442e-01, -2.05633745e-01, -6.00707345e-02, -1.80176944e-02,\n",
              "       -2.09152456e-02, -7.20111728e-02, -4.49218564e-02,  4.39144894e-02,\n",
              "       -5.37205487e-03,  4.73969951e-02, -8.87135863e-02,  2.18831580e-02,\n",
              "        2.87797116e-02, -1.29535403e-02, -1.03977367e-01,  7.81352371e-02,\n",
              "       -1.22202337e-01, -1.03033511e-02, -6.56237006e-02, -9.67411846e-02,\n",
              "       -6.48837984e-02, -3.11636981e-02, -9.04959068e-02, -2.95870658e-02,\n",
              "        4.36350964e-02,  7.04264343e-02, -5.88431470e-02, -6.41893744e-02,\n",
              "        3.23273055e-02, -2.15162765e-02, -5.02031967e-02,  5.04927151e-02,\n",
              "        7.30866790e-02, -4.80472436e-03, -6.68786094e-02, -9.35646519e-02,\n",
              "       -2.37394542e-01,  7.00090528e-02,  5.92781082e-02,  1.29139364e-01,\n",
              "       -2.11542413e-01,  2.16273785e-01, -8.78579915e-02, -2.73688175e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i81dE89eil0-"
      },
      "source": [
        "It is possible to get directly the nearest neighbors of a specific word (or even n-gram)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z86-KCRmiZIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a4603a-c173-4d4e-e2bd-300b753d8740"
      },
      "source": [
        "model.get_nearest_neighbors(\"king\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7550359964370728, 'kings'),\n",
              " (0.7068519592285156, 'queen'),\n",
              " (0.7060439586639404, 'king-'),\n",
              " (0.6811205148696899, 'king.'),\n",
              " (0.660710871219635, 'king.The'),\n",
              " (0.6591265797615051, 'King'),\n",
              " (0.6495252251625061, 'prince'),\n",
              " (0.6278106570243835, '-king'),\n",
              " (0.6183920502662659, 'monarch'),\n",
              " (0.6070184707641602, 'queen-mother')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuDh2zozielx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de12bfa-4361-4700-e0dc-5f469315c7df"
      },
      "source": [
        "model.get_analogies( \"king\", \"man\", \"woman\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7554811835289001, 'queen'),\n",
              " (0.6141632199287415, 'queen-mother'),\n",
              " (0.5755330920219421, 'princess'),\n",
              " (0.5741076469421387, 'monarch'),\n",
              " (0.5688967704772949, 'kings'),\n",
              " (0.5649929046630859, 'queenship'),\n",
              " (0.5638618469238281, 'Queen'),\n",
              " (0.5544734597206116, 'empress'),\n",
              " (0.5524800419807434, 'consort'),\n",
              " (0.5497491955757141, 'queen.The')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aY0iyEosmsy"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://towardsdatascience.com/word-embeddings-in-2020-review-with-code-examples-11eb39a1ee6d\n",
        "\n",
        " https://www.udemy.com/course/nlp-natural-language-processing-with-python"
      ]
    }
  ]
}